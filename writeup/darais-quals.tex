\documentclass{article}

% Boilerplate {{{

\input{setup.tex}

\title{Abstract Control in Static Analysis (Draft)}
\author{David Darais}
\date{\today}

\begin{document}
\maketitle

% }}}

% Abstract {{{
\begin{abstract}

The field of static analysis offers many techniques for automatically discovering facts about programs.
For example, a static analysis might be used to verify that a program is memory safe, or that it obeys a privacy policy.
Techniques based on abstract interpretation allow the analysis designer to vary some properties of an analysis.
However, features like context, object, and flow sensitivity are often hard-coded into a given analysis framework.
One option for altering such features is to redesign an analysis from scratch.
Unfortunately, designing new analyses is a difficult and error-prone process.
Abstracting Abstract Machines (AAM) is a methodology for building analyses which simplifies this process by adhering to a restricted design philosophy.
However, AAM lacks reusable tools for building analyses, and not all analysis features fit nicely into the framework.

We propose a new framework which gives the analysis designer compositional building blocks for designing analyses, and which supports one key feature missing in AAM: abstract control.
We achieve compositionality by refactoring AAM into monad transformers which can be related back to abstract state machines.
When put together, these monad transformers form analyses which are correct by construction.
Using these building blocks we are able to uncover a new tuning knob for static analyses which we call abstract control.
Abstract control allows one to adjust the flow and path sensitivity of an analysis independent of other design choices.

\end{abstract}
% }}}

\tableofcontents

% Introduction {{{
\section{Introduction}
\label{section:Introduction}

% A static analysis has two components: 
% \begin{itemize}
% \item A \emph{computation} which computes some set of facts about the execution of a program.
% \item A \emph{proof of correctness} about the computation.
% \end{itemize}
% 
% We are motivated by static analysis techniques which are:
% \begin{itemize}
% \item Compartmental: Various aspects of the analysis have been separated from each other and are understood in isolation.
% \item Modular: Design choices in one aspect of the analysis do not restrict design choices of another.  
%       This property is important for both computational and correctness components of an analysis.
% \item Language Agnostic: A given analysis technique can be seamlessly transfered from one semantics to another.
% \item Correct: The proof of correctness should exist, and there should be a framework for establishing it.
% \item Derived: Either the computational artifact or the correctness proof should be obtained "for free" from the other.
% \end{itemize}
% 
% Our framework compartmentalizes:
% \begin{itemize}
% \item Abstract domain a la Cousot.
% \item Abstract time and address a la Van Horn and Might.
% \item Intensional optimizations a la Van Horn and Might. 
% \item Object-sensitivity a la Smaragdakis.
% \item Analysis control properties.
% \end{itemize}
% 
% Our framework is:
% \begin{itemize}
% \item Compartmental: Each of the above concerns are separated and independent.
% \item Modular: Design choices in one axis is completely independent of others
% \item Language Agnostic: All axis other than abstract domain are fully language agnostic.
% \item Correct: A correctness framework is described and each axis is proven correct in isolation.
% \item Derived: The correctness of an analysis using our framework comes for free.
% \end{itemize}
% 
% Analysis control properties are the primary topic of this work.
% We merely note that the other axis in the design space are implemented in our framework using existing techniques.
% 
% Contributions:
% \begin{itemize}
% \item Computational artifacts and correctness proofs for the axis of abstract control, which captures the choice of flow and path sensitivity.
% \item Computational artifacts and correctness proofs for intensional optimizations (gargabe collection and mcfa) independent of abstract control.
% \item Language independent proofs of refinement for flow-sensitivity and path-sensitivity choices using the monadic abstraction.
% \end{itemize}
 
% }}}

% Background {{{
\section{Background}
\label{section:Background}
 
% Notation {{{
\subsection{Notation}
\label{section:Background:Notation}

We use traditional notation for function definitions and applications rather than lambda calculus notation.
For example, we will write:
\begin{equation*}
compose(g, f, x) â‰” g(f(x))
\end{equation*}
rather than:
\begin{equation*}
compose\; g\; f\; x â‰” g\; (f\; x)
\end{equation*}

We use lambda notation for anonymous functions.
For example, the anonymous composition function is written:
\begin{equation*}
Î»(g, f, x) â†’ g(f(x))
\end{equation*}

% }}}

% Monads {{{
\subsection{Monads}
\label{section:Background:Monads}

A basic familiarity with the concept of monads will be necessary for understanding this paper.
Some find it useful to review the concept of functor before learning about monads. 
We adopt this approach for our brief explanation of monads.

A type $(F : Set â†’ Set)$ is called a \emph{functor} if one can:
\begin{itemize}
\item Define $map : âˆ€ (A, B : Set), (A â†’ B) â†’ (F(A) â†’ F(B))$
\item Prove $map(id) = id$, where $id$ is the identity function $(Î»(x) â†’ x)$
\item Prove $map (g âˆ˜ f) = map(g) âˆ˜ map(f)$
\end{itemize}

\paragraph{Example:} 
Lists are functors, where $map$ is defined:
\begin{align*}
    map(f)(xs) â‰” &\case(xs):           \\
          Nil    &â†’ Nil                \\
         x âˆ· xs' &â†’ f(x) âˆ· map(f)(xs') \\
\end{align*}

\paragraph{Example:} $map(isEven)([1, 2, 3, 4]) = [False, True, False, True]$

Likewise a type $(â„³  : Set â†’ Set)$ is called a \emph{monad} if one can:
\begin{itemize}
\item Define $extend : âˆ€ (A, B : Set), (A â†’ â„³ (B)) â†’ (â„³ (A) â†’ â„³ (B))$
\item Prove unit and associativity laws (not mentioned here).
\end{itemize}
The only difference from the definition of functor is in the the first argument.
For monads, this argument is allowed to be a \emph{monadic} $(A â†’ â„³ (B))$, rather than a pure function $(A â†’ B)$.

\paragraph{Example:} Lists are monads, where $extend$ is defined:
\begin{align*}
    extend(f)(xs) â‰” &\case(xs):              \\
                Nil &â†’ Nil                   \\
            x âˆ· xs' &â†’ f(x) â§º extend(f)(xs') \\
\end{align*}

\paragraph{Example:} 
$extend(Î»(x) â†’ [x + 1, x - 1])([10, 100]) = [9, 11, 99, 101]$

$extend$ for lists can also be understood as $concat$ followed by $map$:
\paragraph{Example:} 
\begin{align*}
extend(f)([10, 100]) &= concat(map(f)([10, 100]))    \\
                     &= concat([[9, 11], [99, 101]]) \\
                     &= [9, 11, 99, 101]             \\
\end{align*}
For all monads, it is equivalent to define $return$, $map$ and $join$, where:
\begin{equation*}
join : âˆ€ (A : Set), â„³ (â„³ (A)) â†’ â„³ (A)
\end{equation*}
As we have just seen, $join$ for the list monad is just $concat$.

% }}}

% Monad Transformers {{{
\subsection{Monad Transformers}
\label{section:Background:MonadTransformers}

Monad transformers are functions between monads.
Where a monad $â„³ $ will have type $Set â†’ Set$, a monad transformer $ğ’¯$ will have type $(Set â†’ Set) â†’ (Set â†’ Set)$.

Monad transformers are used to extend an existing monad to support another effect.
The three monads used in this work are the state monad, powerset monad, and the identity monad.
The state monad is notated $\SM(ğ“ˆ)$ (carrying a single cell of type $ğ“ˆ$), the powerset monad is notated $\PM$, and the identity is notated $ID$.
The state and powerset monad transformer equivalents are notated $\ST(ğ“ˆ)(â„³ )$ and $\PT(â„³ )$ where $â„³ $ is the underlying monad.
The state monad has $get$ and $put$ effects, whereas the powerset monad has a $nondeterminism$ effect.
The transformer versions of both of these monads allow you to combine effects piecewise.

\paragraph{Example:}
$\ST(â„¤)(\PT(ID))$ is a monad which has $get$ and $put$ effects for a single cell of integer state, in addition to nondeterminism effects.

The definitions, details and proofs of all monads used in our work are given in section \ref{section:Proofs}.

% }}}

% Small Step Semantics {{{
\subsection{Small-Step Semantics}
\label{section:Background:SmallStepSemantics}

This work follows the small-step operational approach to language semantics pioneered by Plotkin and Felleisen.
In small-step operational semantics, the meaning of an expression $e$ of a language is given by the transitive closure of some step relation $e â†¦ e'$.
This yields a state-machine approach to semantics.
Exploring the meaning of $e$ reduces to exploring all possible transitions reachable from $e$ through $â†¦$.
This contrasts to previously developed deontational approaches, where the meaning of $e$ must be given all at once by a denotation function $âŸ¦ e âŸ§$.
This denotation function can quickly demand lots of mathematical machinery.
Small-step operational methods side-step the need for such machinery.

The small-step operation framework supports arbitrary step relations $e â†¦ e'$.  
However for our purposes $â†¦$ will be always be a function-like form of \emph{decidable} relation, i.e. a multifunction.

% }}}

% Abstract Interpretation {{{
\subsection{Abstract Interpretation}
\label{section:Background:AbstractInterpretation}

Abstract Iterpretation (AI) is a formal framework for program analysis pioneered by Cousot and Cousot.
In the setting of abstract interpretation, a program analysis is just an alternate semantics over an abstract domain.
To distinguish the original semantics from the alternate semantics we call the original semantics the \emph{concrete} semantics.
The alternate semantics is called the \emph{abstract} semantics\footnote{
  This terminology quickly becomes confusing because we will eventually construct an abstract machine for both semantics.
  This yields a concrete abstract machine and an abstract abstract machine. 
  This linguistic pun is exploited mercilessly in the work of Might and Van Horn as they â€œabstractâ€ abstract abstract machines, yielding abstract abstract abstract machines.
}.

Consider a concrete language $\C$ and a program in that language $(\Ce : \C)$.
In the AI framework, an analysis for $\Ce$ is:
\begin{itemize}
\item 
  An abstract language $\A$.
\item 
  A relationship between $\C$ and $\A$ that defines when some $(\Ce' : \C)$ and $(\Ae' : \A)$ are related.
  This often takes the form of projecting $\A$ to $\PM(\C)$ and using the subset relation.
\item 
  An abstract version of $\Ce$ our concrete program: $(\Ae : \A)$.
\item 
  An abstract version of the $\Csteps$ relation: $(\Asteps : \A Ã— \A â†’ Prop)$
\item 
  A method to explore every state reachable by $\Ae$ under $\Asteps$.
  This often requires $\A$ to be finite.
\end{itemize}
By convention, we put hats ($\widehat{\;\;}$) on things to name their abstract cousins.
The overall approach is summarized in the following picture:
\input{diagrams/AI.tikz}
This picture takes place at some point in the analysis process.
$\Ce$ is the current program (possibly the result of running the base program for a little while).
$\Ae$ is a valid abstraction of $\Ce$, where this validity is expressed by some relation $R$ holding between $\Ce$ and $\Ae$.
$\Ce'$ is some next state of execution of $\Ce$, and likewise for $\Ae$/$\Ae'$.
In order to be a correct analysis, it must be guaranteed that $\Ce'$ and $\Ae'$ will be related.
The logical structure of the picture, which states the correctness of the analysis, is given by:
\begin{equation*}
âˆ€ (\Ce,\Ce' : \C ) (\Ae,\Ae' : \A), (\Ce R \Ae) âˆ§ (\Ce \Csteps \Ce') âˆ§ (\Ae \Asteps \Ae') â‡’  (\Ce' R \Ae')
\end{equation*}
The \emph{meaning} of the analysis is entirely subject to the relation $R$ which relates the abstract to the concrete.

% }}}

% Galois Connections {{{
\subsection{Galois Connections}
\label{section:Background:GaloisConnections}

The AI setting can be elegently simplified and enriched through the use of \emph{galois connections}.
Galois connections serve as a unifying framework for establishing the â€œrelationship between $\C $ and $\A$â€ mentioned in the previous section.

A galois connection between two posets (sets with a partial order) $\C$ and $\A$ is notated $\C\galois{Î±}{Î³}\A$ and contains:
\begin{itemize}
\item $(Î± : \C â†’ \A)$ where $Î±$ is monotonic
\item $(Î³ : \A â†’ \C )$ where $Î³$ is monotonic
\item A proof that $(Î³ âˆ˜ Î±)$ is expansive: $âˆ€ (x : \C ), x âŠ‘ Î³(Î±(x))$
\item A proof that $(Î± âˆ˜ Î³)$ is contractive: $âˆ€ (y : \A), Î±(Î³(y)) âŠ‘ y$
\end{itemize}
The last two properties can be succinctly stated as $(Î± âˆ˜ Î³ âŠ‘ id âŠ‘ Î³ âˆ˜ Î±)$\footnote{
  This uses the logical monotonicity relation $f âŠ‘ g â‡”  (x âŠ‘ y â‡’  f(x) âŠ‘ g(y))$ for the function space.
}.
Equivalent to all four properties is the property $x âŠ‘ Î³(y) â‡”  Î±(x) âŠ‘ y$.

The expansive property corresponds to \emph{soundness}, and the contractive property corresponds to \emph{tightness}.
A sound analysis gives results you can trust.  
A tight analysis promises to be the â€œbestâ€ analysis possible.

\paragraph{Example:}
Given a galois connection $\C\galois{Î±}{Î³}\A$, there exists a galois connection $(\C â†’ \C)\galois{Î±'}{Î³'}(\A â†’ \A)$ where:
\begin{align*}
Î±'(f : \C â†’ \C) &â‰” Î± âˆ˜ f âˆ˜ Î³ \\
Î³'(g : \A â†’ \A) &â‰” Î³ âˆ˜ g âˆ˜ Î± \\
\end{align*}

\paragraph{Example:} 
The language $(\PM(â„¤),+,*)$ forms a galois connection with the language $(\PM(\{ EVEN, ODD \}),âˆ§,âˆ¨)$ where:
\begin{align*}
Î±(zs : \PM(â„¤))               &â‰” â‹ƒ \{ \{ EVEN  \;|\; âˆƒ z âˆˆ zs âˆ§ Even(z) \},  \{ ODD   \;|\; âˆƒ z âˆˆ zs âˆ§ Odd(z) \} \} \\
Î³(ts : \PM(\{ EVEN, ODD \})) &â‰” â‹ƒ \{ \{ z âˆˆ â„¤ \;|\; EVEN âˆˆ ts âˆ§ Even(z) \}, \{ z âˆˆ â„¤ \;|\; ODD âˆˆ ts âˆ§ Odd(z) \} \} \\
\end{align*}

Galois connections simplify the AI framework by using $x âŠ‘ Î³(y)$ or (equivalently) $Î±(x) âŠ‘ y$ as the relation $(x R y)$.
Galois connections are a natural and general way of placing partial orders \emph{on sets themselves}.
$x âŠ‘ Î³(y)$ can be seen as a heterogenous extension of $x âŠ‘ y$ when $(x : A)$ and $(y : B)$ live in different sets. 
This heterogenous order is given meaning when there exists a galois connection $A\galois{Î±}{Î³}B$.
One can also think of galois connections as something like an isomorphism, but with a weaker round-trip property.
(An isomorphism would require $Î± âˆ˜ Î³ = id = Î³ âˆ˜ Î±$.)

Using galois connections, the AI framework introduced in the previous section can be re-stated. In the AI framework, an analysis for $\Ce$ is:
\begin{itemize}
\item 
  An abstract language $\A$.
\item 
  A galois connection $\C\galois{Î±}{Î³}\A$.
\item 
  An abstract version of the $\Csteps$ relation: $(\Asteps : \A Ã— \A â†’ Prop)$
\item 
  A way to explore every state reachable by $\Ae$ under $\Asteps$.
  This often requires $\A$ to be finite.
\end{itemize}
The overall approach is summarized in the following picture:
\input{diagrams/AIGC.tikz}
As before, the logical structure of the picture is given by:
\begin{equation*}
âˆ€ (\Ce,\Ce' : \C ) (\Ae,\Ae' : \A), (\Ce âŠ‘ Î³(\Ae)) âˆ§ (\Ce \Csteps \Ce') âˆ§ (\Ae \Asteps \Ae') â‡’  (\Ce' âŠ‘ Î³(\Ae'))
\end{equation*}
The statement of this property can be simplified further as $\Csteps âŠ‘ Î³(\Asteps)$.
This uses the definition of galois connections for function spaces shown in a previous example.

Using a galois connection $\C\galois{Î±}{Î³}\A$ and abstract step function $\Asteps âŠ‘ Î³(\Csteps)$, the analysis story becomes simplified even further:
\begin{itemize}
\item Translate $(\Ce : \C)$ to $(Î±(\Ce) : \A)$
\item Explore all abstract states $\Ae'$ states reachable from $Î±(\Ce)$.
\item All reachable concrete states are summarized by projecting each $Î³(\Ae')$ back to $\C$.
\end{itemize}

The galois connection framework simultaneously guarantees the \emph{soundness} and \emph{tightness} of this method.
Soundness tells us that if we abstract, take an abstract step, and then concretize, then the result is an approximation of taking a concrete step.
Soundness tells us that we can trust the results of the analysis.
\input{diagrams/GCSoundness.tikz}
Tightness tells us that if we concretize, take a concrete step, and then abstract, then the result must be just as precise as taking an abstract step.
Tightness tells us that our abstract step function isn't losing precision unnecessarily, and that our abstract step $\Asteps$ is provably as strong as possible.
\input{diagrams/GCTightness.tikz}

% }}}

% CPS {{{
\subsection{Continuation Passing Style}
\label{section:Background:ContinuationPassingStyle}

We use CPS-IF as an example language to demonstrate the benefits of our framework.
CPS is a syntactically restricted version of the lambda calculus.
CPS-IF is an extension of CPS with conditionals.
We choose CPS because the state machine for the semantics of CPS requires no call stack.
We add conditionals to make things slightly more interesting.

We define the CPS-IF language as follows:
\input{snips/CPS-IF.tex}

CPS-IF supports integer and boolean literals, addition and subtraction by 1, and testing if an integer is greater than or equal to zero.
The essence of CPS is in the syntactic restriction on application forms $a(a)$ and $a(a,a)$.  
Because $a$ cannot be a nested call expression, evaluating a $Call$ requires no evaluation stack.

All lambda calculus terms can be translated to CPS terms through CPS-conversion.
However, because lambda calculus terms are much easier to read, we will use lambda calculus terms for examples.
We display the CPS-converted version of examples where appropriate.

% }}}

% Control Flow Analysis {{{
\subsection{Control Flow Analysis}
\label{section:Background:ControlFlowAnalysis}

Control flow analysis is a class of analysis which is particularly important for higher-order languages.
In non-higher-order languages, it is useful to distinguish control-flow from data-flow.
The control flow of the program is a graph of what functions are called from where.
The data flow of a program is a mapping of which values can flow to which variables.
Traditionally one performs a control-flow analysis first, to find out which functions are called, and a data-flow analysis second, using the results of the control flow analysis.

In higher-order languages, data-flow and control-flow are tightly coupled.
Before you can tell which functions will be called, you need to know how values flow, because functions are themselves values.

We note that the distinction between â€œhigher-orderâ€ languages and â€œnon-higher-orderâ€ languages is a red herring.
Functions can be passed as values in C using function pointers, and object-oriented languages enjoy a similar circularity between control- and data- flow due to method dispatch.
You can read these statements as saying â€œall languages are higher order, and thus all languages need higher order control flow analysisâ€.
Or you can read them as saying â€œall languages are higher order, and we've done just fine without higher oder control flow analysis so farâ€.
The real distinction is in the code that you end up analysing.

We build on the tradition of control flow analysis (CFA) pioneered by Shivers, as well as recent refinements of CFA developed by Might and Van Horn.
In this tradition, the result of a control flow analysis is closer to what one would think of as a data-flow analysis, only the process accounts for higher order flow.
0CFA, the most basic control flow analysis, merely computes the set of values which might flow to a particular variable.
kCFA is a suite of context sensitive extensions to 0CFA for which functions are analyzed separately for each possible calling context.
We use 0CFA as the example analysis in this paper.
However our framework, and our implementation of it, scale to the full range of context sensitive control flow analyses.

% }}}

% }}}

% Monadic AAM {{{

\section{Monadic AAM}
\label{section:MonadicAAM}

Monadic abstract interpretation[Sergey et al. PLDI 2013] demonstrated that abstract interpreters can be built modularly using a monadic abstraction.
We build directly on this work at the level of intuitionâ€”monads serve as our pivot-point for achieving modularity.
However, in our pursuit of a modular correctness framework, our approach deviates greatly from prior work in the specific interfaces used.

First we demonstrate a simple 0CFA analysis on CPS-IF which doesn't use our framework.
The CPS-IF language is introduced in section \ref{section:Background:ContinuationPassingStyle}.
We repeat the definition here for convenience.
\input{snips/CPS-IF.tex}

Our abstract semantics of 0CFA will track literals (including lambdas) that appear in the program text.
For integers that do not appear in the program text, the analysis uses a single token $INT$ which conservatively approximates any possible integer.
Formally, the state space $Î£$ for the abstract machine of the abstract semantics is defined as:
\begin{align*}
v : \AVal   &â©´ \INT \;|\; l \;|\; \lam(x) â†’ c \;|\; \lam(x,k) â†’ c \\
Ïƒ : \AStore &â‰” Var â†’ \PM(\AVal)                                   \\
Î£           &â‰” \PM(Call Ã— \AStore)                                \\
\end{align*}
Because there are a finite many literals in the program text, we can claim there are a finite number of possible abstract values.

The abstract semantics for $Î£$ comes in two parts.  
First we define a \emph{denotation function} $ğ’œ $ for $Atom$ expressions.
\begin{align*}
ğ’œ                            &: \AStore Ã— Atom â†’ \PM(\AVal) \\
ğ’œ (Ïƒ,x)                      &â‰” Ïƒ(x)                        \\
ğ’œ (Ïƒ,l)                      &â‰” \{ l \}                     \\
ğ’œ (Ïƒ,\add a) | ğ’œ (Ïƒ,a) âŠ‘ INT &â‰” \{ \INT \}                  \\
ğ’œ (Ïƒ,\sub a) | ğ’œ (Ïƒ,a) âŠ‘ INT &â‰” \{ \INT \}                  \\
ğ’œ (Ïƒ,\gez a) | ğ’œ (Ïƒ,a) âŠ‘ INT &â‰” \{ \TRUE , \FALSE \}        \\
ğ’œ (Ïƒ,\lam(x) â†’ c)            &â‰” \{ \lam(x) â†’ c \}           \\
ğ’œ (Ïƒ,\lam(x)(k) â†’ c)         &â‰” \{ \lam(x)(k) â†’ c \}        \\
\end{align*}

Second we define a \emph{step relation} (as a function) $ğ’$ for $Call$ expressions.
\begin{align*}
ğ’                        : &Call Ã— \AStore â†’ \PM(Call Ã— \AStore)                                              \\
ğ’(\iif(a)\{câ‚\}\{câ‚‚\},Ïƒ) â‰” &\{ (c,Ïƒ)                                                                          \\
                           &|\; c âˆˆ â‹ƒ \{ \{ câ‚ \;|\; \TRUE âˆˆ ğ’œ (Ïƒ,a) \}, \{ câ‚‚ \;|\; \FALSE âˆˆ ğ’œ (Ïƒ,a) \} \} \\
                           &\}                                                                                \\
ğ’(aâ‚(aâ‚‚,aâ‚ƒ),Ïƒ)           â‰” &\{ (c,Ïƒ')                                                                         \\
                           &|\; (\lam(x)(k) â†’ c) âˆˆ ğ’œ (Ïƒ,aâ‚)                                                   \\
                           &|\;             vâ‚‚ âˆˆ ğ’œ (Ïƒ,aâ‚‚)                                                     \\
                           &|\;             vâ‚ƒ âˆˆ ğ’œ (Ïƒ,aâ‚ƒ)                                                     \\
                           &|\;             Ïƒ' â‰” Ïƒ âŠ” [x â†¦ vâ‚‚] âŠ” [k â†¦ vâ‚ƒ]                                      \\
                           &\}                                                                                \\
ğ’(\halt(a),Ïƒ)            â‰” &\{ (\halt(a),Ïƒ) \}                                                                \\
\end{align*}
(We omit the $(aâ‚(aâ‚‚))$ case. It is directly analogous to $(aâ‚(aâ‚‚,aâ‚ƒ))$).

The complete analysis of a program $c$ is defined as the least fixed point of a \emph{collection semantics} for the relation $ğ’$:
\begin{align*}
\text{analysis} â‰” Î¼(Î£) â†’ \{(c,âŠ¥)\} âŠ” ğ’^{â‹†}(Î£)
\end{align*}
where
\begin{align*}
ğ’^{â‹†}    &: \PM(Call Ã— \AStore) â†’ \PM(Call Ã— \AStore) \\
ğ’^{â‹†}(Î£) &â‰” â‹ƒ \{ ğ’(c,Ïƒ) | (c,Ïƒ) âˆˆ Î£ \}                  \\
\end{align*}
The collecting semantics tracks all states that the program could be in rather than just the final states.

The first insight in monadic static analysis is to abbreviate the definitions of $ğ’œ $ and $ğ’$ using a monad.
At this point, the monad â€œtrickâ€ is nothing more than a technique to simplify the definition of $ğ’œ $ and $ğ’$.
This simplification is similar to how a functional programmer would use a state monad in place of state passing style.

We wll use a powerset monad and state monad transformer to write the analysis in monadic style.
The full definitions of the monads (and their proofs) used throughout this paper are defered to section \ref{section:Proofs}.
Because monad transformers are just fancy names for simple types, we write the equivalent simple type underneath definitions which reference monad transformer.
The monadic conversion of the above analysis is as follows.
\begin{align*}
â„³     &: Set â†’ Set                  \\
â„³ (a) &â‰” \ST(\AStore)(\PM)(a)       \\
â„³ (a) &â‰” \AStore â†’ \PM(a Ã— \AStore) \\
\end{align*}

\begin{align*}
ğ’œ                &: Atom â†’ â„³ (\PM(\AVal))                    \\
ğ’œ (x)            &â‰” \ddo                                     \\
                 &Ïƒ â† \getstore                              \\
                 &\return(Ïƒ(x))                               \\
ğ’œ (l)            &â‰” \return(\{l\})                              \\
ğ’œ â‚˜(add1(a))     &â‰” \ddo                                       \\
                 &v â† ğ’œ (a)                                  \\
                 &\return(\{\INT \;|\; âˆƒ i âŠ‘ \INT âˆˆ v\})              \\
ğ’œ â‚˜(sub1(a))     &â‰” \ddo                                       \\
                 &v â† ğ’œ (a)                                  \\
                 &\return(\{\INT \;|\; âˆƒ i âŠ‘ \INT âˆˆ v\})              \\
ğ’œ â‚˜(gez(a))      &â‰” \ddo                                       \\
                 &v â† ğ’œ (a)                                  \\
                 &\return(\{\TRUE, \FALSE \;|\; âˆƒ i âŠ‘ \INT âˆˆ v\})      \\
ğ’œ â‚˜(\lam(x)(k) â†’ c) &â‰” \return(\{\lam(x)(k) â†’ c\})                    \\
\end{align*}

\begin{align*}
ğ’                 &: Call â†’ â„³ (Call)                         \\
ğ’ (\iif(a)\{câ‚\}\{câ‚‚\}) &â‰” \ddo                                      \\
                  &vP â† ğ’œ (a)                                \\
                  &v â† \liftpowerset(vP)                           \\
                  &b â† \coercebool(v)                            \\
                  &\return(\{ \text{if}\; b\; \text{then}\; câ‚\; \text{else}\; câ‚‚ \}) \\
ğ’â‚˜(aâ‚(aâ‚‚,aâ‚ƒ))     &â‰” \ddo                                      \\
                  &vP â† ğ’œ (aâ‚)                               \\
                  &v â† \liftpowerset(vP)                           \\
                  &(\lam(x)(k) â†’ c) â† \coercefun(v)               \\
                  &vPâ‚‚ â† ğ’œ (aâ‚‚)                              \\
                  &vPâ‚ƒ â† ğ’œ (aâ‚ƒ)                              \\
                  &vâ‚‚ â† \liftpowerset(vPâ‚‚)                         \\
                  &vâ‚ƒ â† \liftpowerset(vPâ‚ƒ)                         \\
                  &\modifystore(Î»(Ïƒ) â†’ Ïƒ âŠ” [x â†¦ vâ‚‚] âŠ” [k â†¦ vâ‚ƒ]) \\
                  &\return(c)                                    \\
\end{align*}

The monadic abstraction provides a nice way to simplify the implementation of the analysis.  
In particular, cases which do not modify the store or only return one result.
Both of these cases are instances of having "no effect", and they need not mentioned all members of the state machine.  
(This was observed in Sergey et. al. PLDI 2013.)

As before, we must complete the analysis by building an abstract machine transition function:
\begin{align*}
ğ’^{â‹†}    &: \PM(Call Ã— \AStore) â†’ \PM(Call Ã— \AStore) \\
ğ’^{â‹†}(Î£) &â‰” â‹ƒ \{ ğ’(c)(Ïƒ) \;|\; (c,Ïƒ) âˆˆ Î£ \}             \\
\end{align*}

Our current definition of $â„³ $ used recovers exactly the analysis we wrote before.
On top of the convenience of writing things monadically, our insight and contribution is twofold:
\begin{itemize}
\item $â„³ $ can be \emph{axiomatized}, such that different definitions for $â„³ $ give rise to different control abstractions for the analysis.
\item The monadic abstraction provides for a modular proof framework for establishing the correctness of the analysis.
\end{itemize}

% }}}

% Abstract Control {{{
\section{Abstract Control}
\label{section:AbstractControl}

The current instantiation of â„³  yields a flow-sensitive path-sensitive analysis.  
Consider a reordering of the powerset\footnote{
  The definition of $\PT$ we use is non-traditional.  However, our definition
  for $\PT$ is actually a monad, whereas traditional definitions are not.  Our
  definition and proofs for $\PT$ are given in section \ref{section:Proofs}.
}
and state monad transformers:
\begin{align*}
â„³     &: Set â†’ Set                  \\
â„³ (a) &â‰” \PT(\SM(\AStore))(a)       \\
â„³ (a) &â‰” \AStore â†’ \PM(a) Ã— \AStore \\
\end{align*}

As before, we must convert between monadic actions and abstract state space transitions to achieve an analysis:
\begin{align*}
ğ’^{â‹†}       &: \PM(Call) Ã— \AStore â†’ \PM(Call) Ã— \AStore                                         \\
ğ’^{â‹†}(cP,Ïƒ) &â‰” (\{ c' \;|\; c' âˆˆ Ï€â‚(ğ’(c))(Ïƒ) \;|\; c âˆˆ c\PM \}, â‹ƒ \{ Ï€â‚‚(ğ’(c))(Ïƒ) \;|\; c âˆˆ cP \}) \\
\end{align*}
This instantiation of $â„³ $ and $ğ’*$ yields a flow-insensitive analysis.

For the same monad $â„³ $, we can change the definition of $ğ’*$ to achieve a flow-sensitive path-insensitive analysis:
\begin{align*}
ğ’^{â‹†}    &: \PM(Call Ã— \AStore) â†’ \PM(Call Ã— \AStore)             \\
ğ’^{â‹†}(Î£) &â‰” \{ (c',Ï€â‚‚(ğ’(c))(Ïƒ)) \;|\; c' âˆˆ Ï€â‚(ğ’(c))(Ïƒ) \;|\; (c,Ïƒ) âˆˆ Î£ \} \\
\end{align*}

In the correctness framework, both the flow-sensitive path-sensitive analysis and flow-insensitive analyses are justified through isomorphisms between monadic actions and abstract state space transitions.  
The flow-sensitive path-insensitive variant is recovered by weakening this isomorphism to a galois connection.

% }}}

% Intensional Optimizations {{{

\section{Intensional Optimizations}
\label{section:IntensionalOptimizations}

Up to this point we have factored the abstract control properties of static analysis behind a common interface.  
Now we show how to implement two intentional optimizations, abstract garbage collection and mcfa, in a completely general setting.

\paragraph{Abstract Garbage Collection}
Abstract garbage collection is a technique in abstract interpretation where unreachable abstract addresses are pruned from the state space.
This is analagous to â€œrealâ€ garbage collection, where unreachable pointers are reclaimed for space efficiency.
However, in abstract semantics, addresses are \emph{re-used} to soundly and finitely aproximate an infinite address space.
Impreceision in control flow analyses arise when an abstract address present in the current store must be used for allocation.
Abstract garbage collection is a purely precision and performance improving optimization which removes unreachable abstract addresses.

For a generic implementation of garbage collection we assume an arbitrary $â„³ $ that has $get$, $put$ and nondeterminism effects.
Using this axiomatized interface for $â„³ $, abstract garbage collection can be implemented once in a purely generic way.
\begin{align*}
gc    &: Call â†’ â„³ (1)                                        \\
gc(c) &â‰” \ddo                                                  \\
      &Ïƒ â† \getstore                                             \\
      &ğ“‰â‚€ â† \touchedcall(c)                                           \\
      &\llet ğ“‰ â‰” Î¼(ğ“‰) â†’ ğ“‰ âŠ” \touchedvar(ğ“‰)                           \\
      &\modifystore (Î»(Ïƒ) â†’ â‹ƒ \{ [x â†¦ v] | x âˆˆ ğ“‰ âˆ§ Ïƒ(x) = v \} ) \\
\end{align*}
This is literally the implementation of \emph{concrete} garbage collection.
However, because we have not yet committed to the underlying monad, it seamlessly becomes abstract garbage collection when instantiated with the appropriate monad.

\paragraph{MCFA}
MCFA is an optimization that improves the asymptotic complexity of context-sensitive control flow analyses.
kCFA explodes exponentially for $k > 0$ in functional analyses, causing extremely poor analysis performance in the worst case.
However, an apparent paradox was discovered as kCFA was proven to be polynomial in the worst case for object-oriented programs.
MCFA resolved the paradox by identifying the difference in analyses and transfering the polynomial behavior to functional analysis.
The key insight of MCFA is to use packed, copied closures rather than linked closures in the abstract semantics.

So far our analysis has not used closures for abstract values; 0CFA only tracks lambdas without their closing context.
Adding closures to abstract values is a straightforward addition to the examples we've shown.
(Our implementation implements all of these features in full.)

The mcfa optimization of copying rather than linking closures similarly enjoys a fully generic implementation:
\begin{align*}
  Ï : Env  &â‰”  Var â‡€ \widehat{Addr}                       \\
clo : Clo  &â©´ <\lam(x) â†’ c, Ï> \;|\; <\lam(x,k) â†’ c, Ï>   \\
\end{align*}

\begin{align*}
clo-copy    &: Lam â†’ â„³ (Clo)                               \\
clo-copy(l) &â‰” \ddo                                        \\
            &\llet ys â‰” \operatorname{free-vars}(l)        \\
            &vs â† map^{â‹†}(lookup)(ys)                      \\
            &Ï â† \{ y â†¦^{â‹†} v \;|\; (y,v) âˆˆ zip(ys, vs) \} \\
            &\return (l,Ï)                                 \\
\end{align*}

Using existing techniques, these optimizations would need to be both implemented and proven correct for each instantiation of abstract control.
Our generalization over abstract control allows us to implement each of these optimizations once.
More importantly, the correctness of these optimizations can be established generically as well.

% }}}

% Correctness Framework {{{

\section{Correctness}
\label{section:Correctness}

The key advantage to our framework is that the proofs of correctness for constructed analyses are derived automatically.
To establish the correctness of the monadic approach, we do not merely inline the definitions and resort to reasoning about fully instantiated instances of monadic definitions.
Instead, we relate monadic actions directly to abstract state space transitions for each monad transformer combination.
Given these proofs, along with an argument about monotonicity of the monadic semantics, we can establish a proof of galois connection for any given interpreter instantiation.

To relate back to small step semantics, we establish a galois connection between monadic actions in $â„³ $ and transitions functions for \emph{some} abstract state space $ğ’®ğ’®$.
This abstract state space is constructed from the monad transformer stack, although some transformer stacks support multiple abstract state spaces.
This property is notated $(A â†’ â„³ (B))\galois{Î±}{\gamma}(ğ’®ğ’®(A) â†’ ğ’®ğ’®(B))$.
We call a particular monad $â„³ $ which enjoys this property a \emph{small-step monad}.
Likewise, we call a monad transformer $ğ’¯$ which enjoys \emph{transports} this property a \emph{small-step monad transformer}.

In our framework we prove that not only are $\ST$ and $\PT$ monad transformers, they're small-step monad transformers.
This means that for any stack of interleaving $\ST$ and $\PT$ monad transformers, one can construct the necessary galois connection back to small step semantics.

We prove that $\ST(ğ“ˆ)(\PM) âŠ‘ \PT(\SM(ğ“ˆ))$.
These monad interleavings correspond to path-sensitivity and path-insensitivity respectively.

For the $\PT(\SM(ğ“ˆ))$ monad, we show two galois connections are possible to the state space $\PM(\_ Ã— ğ“ˆ)$.
These choices for galois connection correspond to flow-sensitivity and flow-insensitivity respectively.

Independent of language or application we have proven:
\begin{align*}
flow-insensitive âŠ‘ flow-sensitive path-insensitive âŠ‘ flow-sensitive 
\end{align*}

A given concrete semantics will always use the flow-sensitive path-sensitive monad.
We can use this bridge to construct a galois connection between concrete and a flow-insensitive abstract semantics.

When using our framework, the analysis designer need only prove prove:
\begin{itemize}
\item The semantic step function $ğ’$ is monotonic.
\item The semantics as written, including intensional optimizations, are correct.
\end{itemize}
After supplying these proofs, the analysis designer enjoys:
\begin{itemize}
\item An automatically derived analysis for their language with their choice of abstract control.
\item A proof-by-construction of galois connection (soundness and tightness) for the derived analysis.
\item Seamless extensions to AAM and intensional optimizations (like gc or mcfa), which we demonstrate in our implementation.
\end{itemize}

Our proof technique is maximally modular in that new monads can be composed seamlessly into the framework with disruption.
This modularity greatly reduces the proof burden on the analysis designer as new languages and analyses are developed.

In practice, there will be many more state space components, like abstract time and abstract address in the AAM framework.
To add these features, the analysis designer need only stack more state space monads together to augment the resulting abstract state machine.
However, once monotonicity of the $ğ’$ action is established, both concrete and abstract interpreters can be derived for free.
This is only possible because all proofs have been decomposed to the unit of monad transformer, and these extensions reduce to just adding more transformers to the stack.

% }}}

% Proofs {{{

\section{Proofs}
\label{section:Proofs}

% Basic Definitions {{{
\subsection{Basic Definitions}
\label{section:Proofs:BasicDefinitions}

\begin{definition}
For a type $(A : Set)$, a \emph{partial order} structure on $A$ contains an operator:
\begin{align*}
\_âŠ‘\_ : A â†’ A â†’ Prop
\end{align*}
which respect the following properties:
\begin{align*}
 \operatorname{reflexivity} &: x âŠ‘ x                   \\
\operatorname{antisymmetry} &: x âŠ‘ y â‡’  y âŠ‘ x â‡’  x = y \\
\operatorname{transitivity} &: x âŠ‘ y â‡’  y âŠ‘ z â‡’  x âŠ‘ z \\
\end{align*}
\end{definition}

\begin{definition}
For types $(A, B : Set)$ which both have partial orders, a function $(f : A â†’ B)$ is called \emph{monotonic} if:
\begin{align*}
âˆ€ (x, y : A), x âŠ‘ y â‡’  f(x) âŠ‘ f(y)
\end{align*}
\end{definition}

\begin{lemma}
For types $(A, B : Set)$ which both have partial orders, there exists a partial order on the \emph{monotonic} function space $(A â†’^{mon} B : Set)$ with operator:
\begin{align*}
f âŠ‘ g â‰” âˆ€ (x, y : A), x âŠ‘ y â†’ f(x) âŠ‘ g(y)
\end{align*}
\begin{proof}
Reflexivity is justified by monotonicity.  
Antisymmetry and transitivity are justified through the partial orders on $A$ and $B$.
\end{proof}
\end{lemma}

\begin{definition}
For types $(C, A : Set)$ which both have partial orders, a \emph{galois connection} between $C$ and $A$, written $C\galois{Î±}{Î³}A$, contains two operators:
\begin{align*}
Î± &: C â†’ A \\
Î³ &: A â†’ C \\
\end{align*}
which respect the following properties:
\begin{align*}
                           &Î± \text{is monotonic} \\
                           &Î³ \text{is monotonic} \\
\operatorname{contractive} &: Î± âˆ˜ Î³ âŠ‘ id          \\
  \operatorname{expansive} &: id âŠ‘ Î³ âˆ˜ Î±          \\
\end{align*}
\end{definition}

\begin{definition}
For a type $(A : Set)$, we call $A$ a \emph{join semilattice}, written $JoinSemilattice(A)$, if one can define two operators:
\begin{align*}
    âŠ¥ &: A         \\
\_âŠ”\_ &: A â†’ A â†’ A \\
\end{align*}
which respect the following properties:
\begin{align*}
    \operatorname{left-unit} &: âŠ¥ âŠ” x = x                  \\
   \operatorname{right-unit} &: x âŠ” bot = x                \\
\operatorname{associativity} &: x âŠ” (y âŠ” z) = (x âŠ” y) âŠ” z  \\
\operatorname{commutativity} &: x âŠ” y = y âŠ” x              \\
\end{align*}
\end{definition}

\begin{definition}
For a type $(F : Set â†’ Set)$, we call $F$ a \emph{functor}, written $Functor(F)$, if one can define the operator:
\begin{align*}
\operatorname{map} : âˆ€ (A , B : Set), (A â†’ B) â†’ (F(A) â†’ F(B))
\end{align*}
which respects the following properties:
\begin{align*}
          unit &: map(id) = id                  \\
distributivity &: map(g âˆ˜ f) = map(g) âˆ˜ map(f)  \\
\end{align*}
\end{definition}

\begin{definition}
For a type $(â„³  : Set â†’ Set)$, we call $â„³ $ a \emph{monad}, written $Monad(â„³ )$, if one can define two operators:
\begin{align*}
\operatorname{return} &: âˆ€ (A : Set), A â†’ â„³ (A)                          \\
\operatorname{extend} &: âˆ€ (A, B : Set), (A â†’ â„³ (B)) â†’ (â„³ (A) â†’ (â„³ (B))) \\
\end{align*}
which respect the following properties:
\begin{align*}
    \operatorname{left-unit} &: extend(return) = id                               \\
   \operatorname{right-unit} &: extend(k) âˆ˜ return = k                            \\
\operatorname{associativity} &: extend(kâ‚‚) âˆ˜ extend(kâ‚) = extend(extend(kâ‚‚) âˆ˜ kâ‚) \\
\end{align*}
\end{definition}

\begin{corrolary}
All monads are functors.
\end{corrolary}

\begin{definition}
For a type $(ğ’¯ : (Set â†’ Set) â†’ (Set â†’ Set))$, we call $ğ’¯$ a \emph{monad transformer}, written $Transformer(ğ’¯)$, if one can define a single operator:
\begin{align*}
lift : âˆ€ (â„³  : Set â†’ Set) (A : Set), â„³ (A) â†’ ğ’¯(â„³ )(A)
\end{align*}
and the following property holds:
\begin{align*}
âˆ€ (â„³  : Set â†’ Set), Monad(â„³ ) â‡’  Monad(ğ’¯(â„³ ))
\end{align*}
\end{definition}

\begin{definition}
For types $(ğ“ˆ : Set)$ and $(â„³  : Set â†’ Set)$, we call $â„³ $ a \emph{monad state over $ğ“ˆ$}, written $MonadState(ğ“ˆ)(â„³ )$, if one can define operators:
\begin{align*}
\operatorname{get} &: â„³ (ğ“ˆ)     \\
\operatorname{put} &: ğ“ˆ â†’ â„³ (1) \\
\end{align*}
\end{definition}

\begin{definition}
For a type $(â„³  : Set â†’ Set)$, we call $â„³ $ a \emph{monad plus}, written $MonadPlus(â„³ )$, if the following property holds:
\begin{align*}
âˆ€ (A : Set), JoinSemilattice(â„³ (A))
\end{align*}
and the following additional properties hold:
\begin{align*}
     \operatorname{left-zero} &: extend(k)(âŠ¥) = âŠ¥                               \\
    \operatorname{right-zero} &: extend(const(âŠ¥))(x) = âŠ¥                        \\
\operatorname{distributivity} &: extend(k)(x âŠ” y) = extend(k)(x) âŠ” extend(k)(y) \\
\end{align*}
\end{definition}

\begin{definition}
For types $(â„³  , ğ’®ğ’® : Set â†’ Set)$, we call $â„³ $ a \emph{small step monad with state space $ğ’®ğ’®$}, written $MonadSmallStep(ğ’®ğ’®)(â„³ )$, if one can define:
\begin{align*}
âˆ€ (A, B : Set), (A â†’ â„³ (B)) \galois{Î±}{Î³} (ğ’®ğ’®(A) â†’ ğ’®ğ’®(B))
\end{align*}
\end{definition}

\begin{definition}
For a type $(F : Set â†’ Set)$ and property $(P : Set â†’ Prop)$, we call $F$ \emph{functorial in $P$}, written $Functorial(P)(F)$, if the following property holds:
\begin{align*}
âˆ€ (A : Set), P(A) â‡’ P (F(A))
\end{align*}
and all operations in $P$ distribute through monadic operations in $F$.
\end{definition}

\begin{example}
For a type $(F : Set â†’ Set)$ to be \emph{functorial in $JoinSemilattice$}, the following additional laws must hold:
\begin{align*}
return (x âŠ” y) = return(x) âŠ” return(y)
\end{align*}
\end{example}

% }}}

% ID {{{
\subsection{ID}
\label{section:Proofs:ID}

\begin{definition}
The \emph{identity monad}, written $ID$, is defined:
\begin{align*}
   ID &: Set â†’ Set \\
ID(A) &â‰” A         \\
\end{align*}
\end{definition}

\begin{lemma}
The identity monad is a monad with operators:
\begin{align*}
return &â‰” id \\
extend &â‰” id \\
\end{align*}
\begin{proof}
Unit and associativity laws are established trivially by definition.
\end{proof}
\end{lemma}

\begin{lemma}
The identity monad is \emph{functorial in all structures}.
\begin{proof}
Holds by definition of $ID$.
\end{proof}
\end{lemma}

% }}}

% SetT {{{
\subsection{$\PT$}
\label{section:Proofs:SetT}

\begin{definition}
The \emph{set monad transformer}, written $\PT$, is defined:
\begin{align*}
\PT(â„³ )(A) â‰” â„³ (\PM(A))
\end{align*}
\end{definition}

\begin{lemma}
For a given $(â„³  : Set â†’ Set)$ where:
\begin{itemize}
\item $â„³ $ is a monad.
\item $â„³ $ is functorial in JoinSemilattice.
\end{itemize}
then $\PT(â„³ )$ is a monad plus.
\begin{proof}
By applying functoriality of $â„³ $ to the semilattice $\PM$.
\end{proof}
\end{lemma}

\begin{lemma}
For a given $(â„³  : Set â†’ Set)$ where:
\begin{itemize}
\item $â„³ $ is a monad.
\item $â„³ $ is functorial in JoinSemilattice.
\end{itemize}
then $\PT(â„³ )$ is a monad with operators:
\begin{align*}
   return &â‰” return_{â„³ } âˆ˜ singleton \\
extend(k) &â‰” extend_{â„³ }(joins âˆ˜ map_{\PM}(k))  \\
\end{align*}
\begin{proof} of left unit.
\begin{align*}
\operatorname{left-unit} &: extend(return) = id                                                                                        \\
                                                                                                                                       \\
extend(return) &= extend_{â„³ }(joins âˆ˜ map_{\PM}(return_{â„³ } âˆ˜ singleton_{\PM}))            \tag{definition of extend and join}         \\
               &= extend_{â„³ }(Î»(xs) â†’ â‹ƒ \{ return_{â„³ } (singleton_{\PM}(x)) \;|\; x âˆˆ xs \}) \tag{definition of joins}                 \\
               &= extend_{â„³ }(Î»(xs) â†’ return_{â„³ } (â‹ƒ \{ singleton_{\PM}(x) \;|\; x âˆˆ xs \})) \tag{functorality of semilattice in $â„³ $} \\
               &= extend_{â„³ }(Î»(xs) â†’ return_{â„³ }(xs))                                       \tag{join identity for $\PM$}             \\
               &= extend_{â„³ }(return_{â„³ })                                                 \tag{Î· reduction for Î»}                     \\
               &= id                                                                       \tag{left unit monad law for $â„³ $}          \\
\end{align*}
\end{proof}
\begin{proof} of right unit.
\begin{align*}
\operatorname{right-unit} &: extend(k)(return(x)) = k(x)                                                                                 \\
                                                                                                                                         \\
extend(k)(return(x)) &= extend_{â„³ }(joins âˆ˜ map_{\PM}(k))(return_{â„³ }(singleton_{\PM}(x))) \tag{definition of extend and join}           \\
                     &= joins(map_{\PM}(k)(return_{â„³ }(singleton_{\PM}(x))))               \tag{right unit monad law for $â„³ $}           \\
                     &= joins(return_{â„³ }(singleton_{\PM}(k(x))))                          \tag{map distribution law for $â„³ $ and $\PM$} \\
                     &= k(x)                                                               \tag{definition of joins}                     \\
\end{align*}
\end{proof}
\begin{proof} of associativity.
\begin{align*}
\operatorname{associativity} &: extend(kâ‚‚) âˆ˜ extend(kâ‚) = extend(extend(kâ‚‚) âˆ˜ kâ‚)                                                              \\
                                                                                                                                               \\
extend(kâ‚‚)âˆ˜ extend(kâ‚) &= extend_{â„³ }(joins âˆ˜ map_{\PM}(kâ‚‚)) âˆ˜ extend_{â„³ }(joins âˆ˜ map_{\PM}(kâ‚)) \tag{definition of $extend$}                 \\
                       &= extend_{â„³ }(extend_{â„³ }(joins âˆ˜ map_{\PM}(kâ‚‚)) âˆ˜ joins âˆ˜ map_{\PM}(kâ‚)) \tag{associativity law for $â„³ $}             \\
                       &= extend_{â„³ }(extend(kâ‚‚) âˆ˜ joins âˆ˜ map_{\PM}(kâ‚))                         \tag{definition of $extend$}                 \\
                       &= extend_{â„³ }(Î»(xs) â†’ extend(kâ‚‚) (â‹ƒ \{ kâ‚(x) \;|\; x âˆˆ xs\}))             \tag{definitions of $joins$ and $map_{\PM}$} \\
                       &= extend_{â„³ }(Î»(xs) â†’ â‹ƒ \{ extend(kâ‚‚)(kâ‚(x)) \;|\; x âˆˆ xs\})              \tag{distributivity of $âˆª$ for $â„³ $}         \\
                       &= extend_{â„³ }(joins âˆ˜ map_{\PM}(extend(kâ‚‚) âˆ˜ kâ‚))                         \tag{definition of $map_{\PM}$}              \\
                       &= extend(extend(kâ‚‚) âˆ˜ kâ‚)                                                 \tag{definition of $extend$}                 \\
\end{align*}
\end{proof}
\end{lemma}

\begin{lemma}
For a given $(â„³  : Set â†’ Set)$ and $(ğ“ˆ : Set)$ where:
\begin{itemize}
\item $â„³ $ is a monad.
\item $â„³ $ is a monad state over $ğ“ˆ$.
\item $â„³ $ is functorial in JoinSemilattice.
\end{itemize}
then $\PT(â„³ )$ is a monad state over $ğ“ˆ$ with operators:
\begin{align*}
   get    &â‰” map_{â„³ }(singleton)(get_{â„³ })    \\
   put(ğ“ˆ) &â‰” map_{â„³ }(singleton)(put_{â„³ }(ğ“ˆ)) \\
\end{align*}
\end{lemma}

\begin{lemma}
For a given $(â„³  : Set â†’ Set)$ and $(ğ’®ğ’® : Set â†’ Set)$ where:
\begin{itemize}
\item $â„³ $ is a monad.
\item $â„³ $ is a small-step monad over $ğ’®ğ’®$.
\item $â„³ $ is functorial in join semilattice.
\item $ğ’®ğ’®$ is a functor.
\end{itemize}
then $\PT(â„³ )$ is a small step monad over $(ğ’®ğ’® âˆ˜ \PM)$ with galois connection maps:
\begin{align*}
   Î± &: âˆ€ (A, B : Set), (A â†’ \PT(â„³ )(B)) â†’ (ğ’®ğ’®(\PM(A)) â†’ ğ’®ğ’®(\PM(B))) \\
Î±(f) &â‰” Î±_{â„³ }(joins âˆ˜ map_{\PM}(f))                                 \\
                                                                     \\
   Î³ &: âˆ€ (A, B : Set), (ğ’®ğ’®(\PM(A)) â†’ ğ’®ğ’®(\PM(B))) â†’ (A â†’ \PT(â„³ )(B)) \\
Î³(f) &â‰” Î³_{â„³ }(f âˆ˜ map_{ğ’®ğ’®}(return_{\PM}))                           \\
\end{align*}
\begin{proof} of contractivity.
\begin{align*}
Î± âˆ˜ Î³ &âŠ‘ id                                                                   \\
                                                                              \\
(Î± âˆ˜ Î³)(f) &= Î±_{â„³ }(joins âˆ˜ map_{\PM}(Î³_{â„³ }(f âˆ˜ map_{ğ’® ğ’® }(return_{\PM})))) \\
\end{align*}
TODO.
(Requires $Î±(1) = 1$ and $Î±(g âˆ˜ f) = Î±(g) âˆ˜ Î±(f)$ (maybe $âŠ‘$?), and likewise for $Î³$.)
\end{proof}
\begin{proof} of expansivity.
\begin{align*}
\end{align*}
TODO.
\end{proof}
\end{lemma}

\begin{verbatim}

MonadSmallStep(ğ“‚ )(ğ’®ğ’®) âˆ§ (\PM âˆ˜ ğ’®ğ’®) Î±â‡„ Î³ (ğ’®ğ’® âˆ˜ \PM)
-------------------------------------
MonadSmallStep(\ST ğ“‚ )(\PM âˆ˜ ğ’®)

Î± : âˆ€ (A B : Set), (A â†’ \ST(ğ“‚ )(B)) â†’ (\PM(ğ’®ğ’®(A) â†’ \PM(ğ’®ğ’®(B))))
Î±(f) â‰” extendâ‚š(Î± âˆ˜ Î±â‚˜(f))

Î³ : âˆ€ (A B : Set), (\PM(ğ’®ğ’®(A) â†’ \PM(ğ’®ğ’®(B)))) â†’ (A â†’ \ST(ğ“‚ )(B))
Î³(f) â‰” extendâ‚š(Î³ âˆ˜ Î³â‚˜(f))
\end{verbatim}

% }}}

% StateT {{{

\subsection{$\ST$}
\label{section:Proofs:StateT}

\begin{verbatim}
\ST : Set â†’ (Set â†’ Set) â†’ (Set â†’ Set)
\ST(ğ“ˆ)(ğ“‚ )(A) â‰” ğ“ˆ â†’ ğ“‚  (A Ã— ğ“ˆ)

Transformer(\ST(ğ“ˆ))
----------------------

lift : âˆ€ (ğ“‚  : Set â†’ Set) (A : Set), ğ“‚  a â†’ \ST(ğ“ˆ)(ğ“‚ )(A)
lift aM â‰” Î» ğ“ˆ â†’ mapâ‚˜ (,ğ“ˆ) aM

Monad(ğ“‚ )
--------------------
Monad(\ST(ğ“ˆ)(ğ“‚ ))

return : âˆ€ (A : Set), A â†’ \ST(ğ“ˆ)(ğ“‚ )(A)
return â‰” lift âˆ˜ returnâ‚˜

extend : âˆ€ (A B : Set), (A â†’ \ST(ğ“ˆ)(ğ“‚ )(B)) â†’ (\ST(ğ“ˆ)(ğ“‚ )(A) â†’ \ST(ğ“ˆ)(ğ“‚ )(B))
extend(k)(aM) â‰” Î» ğ“ˆ â†’ doâ‚˜
  (a,ğ“ˆ') â† aM(ğ“ˆ)
  k(a)(ğ“ˆ')

JoinSemilattice(ğ“ˆ) âˆ§ Monad(ğ“‚ )
------------------------------------------
Functorial(JoinSemilattice)(\ST(ğ“ˆ)(ğ“‚ ))

bot : \ST(ğ“ˆ)(ğ“‚ )(A)
bot â‰” Î»(ğ“ˆ)â†’ (âŠ¥ â‚›, âŠ¥ â‚)

âŠ” : \ST(ğ“ˆ)(ğ“‚ )(A) â†’ \ST(ğ“ˆ)(ğ“‚ )(A) â†’ \ST(ğ“ˆ)(ğ“‚ )(A)
aMâ‚ âŠ” aMâ‚‚ â‰” Î» ğ“ˆ â†’ doâ‚˜
  (aâ‚,ğ“ˆâ‚) â† aMâ‚
  (aâ‚‚,ğ“ˆâ‚‚) â† aMâ‚‚
  return (aâ‚ âŠ” aâ‚‚, ğ“ˆâ‚ âŠ” ğ“ˆâ‚‚)

MonadPlus(ğ“‚ )
------------------------
MonadPlus(\ST(ğ“ˆ)(ğ“‚ ))

âŠ¥ : âˆ€ (A : Set), \ST(ğ“ˆ)(ğ“‚ )(A)
âŠ¥ â‰” lift âŠ¥ â‚˜

âŠ” : âˆ€ (A : Set), \ST(ğ“ˆ)(ğ“‚ )(A)
aMâ‚ âŠ” aMâ‚‚ â‰” Î» ğ“ˆ â†’ aMâ‚(ğ“ˆ) <+> aMâ‚‚(ğ“ˆ)

Monad(ğ“‚ )
----------------------------
Monad\ST(ğ“ˆ)(\ST(ğ“ˆ)(ğ“‚ ))

get : \ST ğ“ˆ ğ“‚  ğ“ˆ
get â‰” Î» ğ“ˆ â†’ return (ğ“ˆ,ğ“ˆ)

put : ğ“ˆ â†’ \ST ğ“ˆ ğ“‚  1
put(ğ“ˆ) â‰” Î» (ğ“ˆ') â†’ return (âˆ™,ğ“ˆ)

MonadSmallStep(ğ“‚ )(ğ’®ğ’®)
--------------------------------------
MonadSmallStep(\ST(ğ“ˆ)(ğ“‚ ))(ğ’®ğ’®(\_ Ã— ğ“ˆ))

Î± : âˆ€ (A B : Set), (A â†’ \ST(ğ“ˆ)(ğ“‚ )(B)) â†’ (ğ’®ğ’®(A Ã— ğ“ˆ) â†’ ğ’®ğ’®(B Ã— ğ“ˆ))
Î±(f) â‰” Î±â‚˜ (Î» (a,ğ“ˆ) â†’ f(a)(ğ“ˆ))

Î³ : âˆ€ (A B : Set), (ğ’®ğ’®(A Ã— ğ“ˆ) â†’ ğ’®ğ’®(B Ã— ğ“ˆ)) â†’ (A â†’ \ST(ğ“ˆ)(ğ“‚ )(B))
Î³(f) â‰” Î»(a,ğ“ˆ) â†’ Î³â‚˜ (f)(a,s)
\end{verbatim}

% }}}

% }}}

% Bibliography {{{
\bibliography{davdar}{}
\bibliographystyle{plain}
% }}}

\end{document}
